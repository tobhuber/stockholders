\documentclass[12pt,a4paper,oneside]{book}

\usepackage{babel}
\usepackage[utf8]{inputenc}


\begin{document}

Three fundamental elements:
\begin{itemize}
\item statistical model describing a method’s general functional form for risk premium
predictions
\item second is an objective function for estimating model parameters
\item even with a small number of predictors, the set of model permutations expands rapidly when one considers nonlinear predictor
transformations.
\end{itemize}

\subsection{Sample Splitting And Tuning Via Validation}
	Hyperparameters (initial parameters set prior to the machine learning process)
	drastically affect the complexity and therefore overall performance of the model.
	An adaptive approach is used where the sample is split into the 3 disjoint time periods
	"training", "validation" and "testing". The "training" period estimates the model
	subject to a specific set of tuning parameter values. The "validation" period
	tunes the parameters by simulating an out-of-sample-test of the model
	to produce reliable out-of-sample performance. The "testing" period is truly
	out-of-sample and therefore is used to evaluate a method’s predictiveperformance.

\subsection{Simple Linear}
	Describing the model by simple linear predictive regression it will perform poorly in a high 
	dimension problem nevertheless we use it as reference point for emphasizing the distinctive 
	features of more sophisticated methods.
	However it does not allow for nonlinear effects or interactions between predictors.
	Yet in some cases it is possible to improve accuracy by using weighted least squares.
	Thus allowing statistically or economically information.
	
\subsection{Penalized Linear}
\subsection{Dimension Reduction: PCR and PLS}
\subsection{Generalized Linear}
\subsection{Boosted Regression Trees and Random Forest}
\subsection{Neural Networks}


\end{document}
